{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textual Entailment\n",
    "\n",
    "With Textual Entailment (TE) the goal is to take a pair of sentences and predict whether the facts in the first sentence necessarily imply the facts in the second one.\n",
    "\n",
    "> An **entailment** is a deduction or implication, that is, something that follows logically from or is implied by something else.\n",
    "\n",
    "### Contradiction example\n",
    "- **Sentence one:** Two women are wandering along the shore drinking iced tea.\n",
    "- **Sentence two:** Two women are sitting on a blanket near some rocks talking about politics.\n",
    "\n",
    "### Entailment example\n",
    "- **Sentence one:** An interplanetary spacecraft is in orbit around a gas giant's icy moon.\n",
    "- **Sentence two:** The spacecraft has the ability to travel between planets.\n",
    "\n",
    "### Neutral example\n",
    "- **Sentence one:** A large, gray elephant walked beside a herd of zebras.\n",
    "- **Sentence two:** The elephant was lost.\n",
    "\n",
    "## Stanford Natural Language Inference corpus\n",
    "\n",
    "With $570{,}152$ sentence pairs the Stanford Natural Language Inference (SNLI) corpus is a large collection of sentence pairs labeled for entailment, contradiction, and semantic independence. See [Bowman et al.](https://nlp.stanford.edu/pubs/snli_paper.pdf) for more info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final exam\n",
    "\n",
    "In this final exam, we expect you to implement three different variants of models that can solve the TE challenge.\n",
    "\n",
    "1. Follow [Bowman et al.](https://nlp.stanford.edu/pubs/snli_paper.pdf)'s solution to build a simple Bag of Words model\n",
    "  - Accuracy goal: 70%\n",
    "2. Follow [Bowman et al.](https://nlp.stanford.edu/pubs/snli_paper.pdf) (same as above) to build a model with an LSTM RNN\n",
    "  - Accuracy goal: 75%\n",
    "3. Follow [McCann et al.](https://arxiv.org/abs/1708.00107) al Biattentive Classification Network (BCN) model elaborated in section five (this is advanced and timeconsuming)\n",
    "  - Accuracy goal: 80%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The data loader\n",
    "\n",
    "`torchtext` has made a convinient data loader for the SNLI dataset.\n",
    "See https://github.com/pytorch/text/blob/master/test/snli.py for details on how to use it.\n",
    "\n",
    "For word vectors use `GloVe 840B` with 300 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use torchtext's data loader for snli\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import stuff\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "def get_variable(x):\n",
    "    \"\"\" Converts tensors to cuda, if available. \"\"\"\n",
    "    return x.cuda() if use_cuda else x\n",
    "\n",
    "def get_numpy(x):\n",
    "    \"\"\" Get numpy array for both cuda and not. \"\"\"\n",
    "    return x.cpu().data.numpy() if use_cuda else x.data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the BoW model\n",
    "class BoWNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BoWNet, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the LSTM model\n",
    "class LSTMNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LSTMNet, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BCN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the BCN model\n",
    "class BCNNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BCNNet, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function, optimizer, and accuracy metric\n",
    "# note, you might want to think about the model first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "net = None # the net you want to use\n",
    "if use_cuda:\n",
    "    net.cuda()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
