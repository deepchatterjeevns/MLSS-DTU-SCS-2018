{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wikitext_RNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "saVJoGox-5yT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "d0b95cd6-3ee8-4b61-a6e2-7304b90895ac"
      },
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/0e/e382bcf1a6ae8225f50b99cc26effa2d4cc6d66975ccf3fa9590efcbedce/torch-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (519.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 519.5MB 28kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x59df0000 @  0x7fbf2b34c1c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "Successfully installed torch-0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7A-VjIvpktU1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import itertools\n",
        "from collections import defaultdict\n",
        "\n",
        "torch.manual_seed(7) # For reproducibility"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TXaZwINHmApf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "next_index = 0\n",
        "def get_new_index():\n",
        "  global next_index\n",
        "  index = next_index\n",
        "  next_index += 1\n",
        "  return index\n",
        "\n",
        "vocabulary = defaultdict(get_new_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "werrIXUYk3hc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "TRAIN_URL = 'https://raw.githubusercontent.com/pytorch/examples/master/word_language_model/data/wikitext-2/train.txt'\n",
        "TRAIN_FILE = 'train.txt'\n",
        "if not os.path.exists(TRAIN_FILE):\n",
        "  import requests\n",
        "  response = requests.get(TRAIN_URL)\n",
        "  assert response.status_code == 200\n",
        "  with open(TRAIN_FILE, 'wb') as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "with open(TRAIN_FILE, 'r', encoding='utf-8') as f:\n",
        "  content = [sentence.split() + ['<eos>'] for sentence in f.read().split(' . ')]\n",
        "  all_words = list(itertools.chain.from_iterable(content))\n",
        "  all_tokens = torch.tensor([vocabulary[word] for word in all_words])\n",
        "  vocab_size = len(vocabulary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kfn9yt3loYca",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class args:\n",
        "  batch_size = 64\n",
        "  seq_len = 32\n",
        "  \n",
        "device = torch.device('cuda')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CMa6Tp5DmPCH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_batched(tokens, batch_size):\n",
        "  # See https://github.com/pytorch/examples/blob/master/word_language_model/main.py#L64-L83 for a comment\n",
        "  data_size = len(tokens) // batch_size * batch_size\n",
        "  tokens = tokens[:data_size]\n",
        "  return tokens.reshape(batch_size, -1).t().contiguous()\n",
        "\n",
        "\n",
        "def get_batch(data, i, seq_len):\n",
        "  # See https://github.com/pytorch/examples/blob/master/word_language_model/main.py#L111-L125 for a comment\n",
        "  seq_len = min(seq_len, len(data) - i - 1)\n",
        "  samples = data[i:i + seq_len]\n",
        "  targets = data[i + 1:i + 1 + seq_len]\n",
        "  return samples, targets\n",
        "  \n",
        "train_data = make_batched(all_tokens, args.batch_size).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eSe86c57sX0n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LanguageModel(nn.Module):\n",
        "  def __init__(self, embedding_size, hidden_size, num_layers):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
        "    self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers)\n",
        "    self.project = nn.Linear(hidden_size, vocab_size)\n",
        "  \n",
        "  def forward(self, input, hidden=None):\n",
        "    embed = self.embedding(input)\n",
        "    rnn_out, new_hidden = self.rnn(embed, hidden)\n",
        "    return self.project(rnn_out), new_hidden\n",
        "  \n",
        "model = LanguageModel(128, 256, 2).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WRDp17Kpobbu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "96713b64-a924-43bd-9757-7ea8e42d4b1d"
      },
      "cell_type": "code",
      "source": [
        "# NOTE: this cell only trains for a single epoch!\n",
        "hidden = None\n",
        "for i, offset in enumerate(range(0, len(train_data), args.seq_len)):\n",
        "  samples, targets = get_batch(train_data, offset, args.seq_len)\n",
        "  output, hidden = model(samples, hidden)\n",
        "  hidden = tuple(h.detach() for h in hidden) # Truncated backpropagation through time\n",
        "  loss = F.cross_entropy(output.reshape(-1, vocab_size),\n",
        "                         targets.reshape(-1))\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  if i % 20 == 0:\n",
        "    print(loss.item())"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.68550443649292\n",
            "5.560492515563965\n",
            "5.43204927444458\n",
            "5.47991943359375\n",
            "5.431942462921143\n",
            "5.395793914794922\n",
            "5.458574295043945\n",
            "5.491985321044922\n",
            "5.347511291503906\n",
            "5.353490829467773\n",
            "5.393863677978516\n",
            "5.554957866668701\n",
            "5.524961471557617\n",
            "5.5842413902282715\n",
            "5.476774215698242\n",
            "5.497668266296387\n",
            "5.560472011566162\n",
            "5.522960186004639\n",
            "5.446229457855225\n",
            "5.542274475097656\n",
            "5.444040775299072\n",
            "5.297715187072754\n",
            "5.384215831756592\n",
            "5.311801910400391\n",
            "5.374419212341309\n",
            "5.489924430847168\n",
            "5.308981895446777\n",
            "5.3434014320373535\n",
            "5.475695610046387\n",
            "5.300534248352051\n",
            "5.329865455627441\n",
            "5.146168231964111\n",
            "5.2738213539123535\n",
            "5.419571399688721\n",
            "5.351753234863281\n",
            "5.357388496398926\n",
            "5.332761764526367\n",
            "5.408023834228516\n",
            "5.387702465057373\n",
            "5.241555213928223\n",
            "5.349188327789307\n",
            "5.347907066345215\n",
            "5.4240007400512695\n",
            "5.21343994140625\n",
            "5.195337772369385\n",
            "5.277040481567383\n",
            "5.3807268142700195\n",
            "5.343599796295166\n",
            "5.40838098526001\n",
            "5.399034023284912\n",
            "5.302357196807861\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FY-UIBVXudo9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc8ed64e-34d8-4234-c4ef-3fc1143bd7f1"
      },
      "cell_type": "code",
      "source": [
        "num_generated_words = 10\n",
        "reverse_vocab = {token: word for word, token in vocabulary.items()}\n",
        "temperature = 1.\n",
        "words = []\n",
        "hidden = None\n",
        "input = torch.randint(vocab_size, (1, 1), dtype=torch.long, device=device)\n",
        "\n",
        "init_words = ['I', 'am']\n",
        "for word in init_words:\n",
        "  input = torch.tensor([[vocabulary[word]]], dtype=torch.long, device=device)\n",
        "  output, hidden = model(input, hidden)\n",
        "  words.append(word)\n",
        "\n",
        "for i in range(num_generated_words):\n",
        "  with torch.no_grad():\n",
        "    word_probs = output.div(temperature).exp().view(-1)\n",
        "    word_idx = torch.multinomial(word_probs, 1).item()\n",
        "    input.fill_(word_idx)\n",
        "    output, hidden = model(input, hidden)\n",
        "    words.append(reverse_vocab[word_idx])\n",
        "print(' '.join(words))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I am practices of her second interpretation , it Gives best centimetres\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}